5.2 从小工到专家

当一个开发者拿到 Docker 文档之后，一定会按捺不住内心的激动，把所有的 Getting Started

跑-遍，当然中间可能会碰到问题，仔细阅读过本书第-一部分的读者应该能更加游刃有余地做完这些事情。甚至尝试过第 4 章的高级玩法后，当第一个 demo 开始工作时，终于可以当仁不让地宣布自己已经是个高级玩家。

那么问题来了：接下来该做什么？

以一个开发者的视角继续往下看，往后事情的发展无外乎两种可能：第一，开发者默默地记住这些技能，然后把 Docker 当作自己的独门武器，以至于最后老板都开始怀疑这家伙的开发效率怎么会突然变得这么高。第二，热心的开发者开始向全组推广 Docker，甚至鼓动运维也加人 Docker 行列。般情况下，我们会称赞第二种开发者为“愿意当将军的士兵”。

于是，我们的“将军开发者”决定从最简单的需求开始演示自己的计划，只用了几分钟，他就搭建好了一个容器集群，如图 5-4 所示。这是一个来自《第一本 Docker 书》的例子，与第 2 章中我们手把手搭建过的“第一个 Docker 集群”有点类似。

在这个组合实例中，他成功地将一个 Node; js 应用运行起来，并且使用 Redis 集群来存储这个应用的 session 信息，最后还使用 ELK 组合（ElasticSearch+Logstash+Kibana）完成了应用和 Redis 的日志转发、存储和检索功能。当然最酷的-一定是这些内容全是跑在 Docker 容器里的，他只用了几条命令外加几分钟的时间就全部搞定了。团队里的其他人只要把 Dockerfile 拿走，几分钟就可以搭建一套一模一样的环境出来！

图 5-4 一个 Node. Js 应用和 ELK 组合的实例

“真不错！”大家纷纷称赞这种基于容器来构建服务栈的方式是多么地优雅。

“可是要上线的话，负载均衡总要有的吧？”一位不大讨，人喜欢的开发经理提出了第一个需求。

的确，在经典互联网应用场景里，无论后端系统多么地复杂强大，最前面放置的一般都该是负载均衡设备而非 Web 服务器，并且负载均衡这--环节还有很多必须额外设定的配置（比如 session sticky、静态动态内容分离、URL 重定向等）。在此基础上，应用还往往被复制成多份，在负载均衡管理下统一提供对外服务，这项技术对于分流、灰度发布、高可用以及弹性伸缩都是必需的。好在有了 Docker 的帮助，这一-切都不算难，“将军开发者”挠挠头的功夫就 build 了一个 HAProxy 镜像启动起来，然后又启动了一个完全相同的 Node. Js 应用的容器（得益于镜像，这类操作非常便捷），最后将两个应用容器的 IP 和端口配置到了 HAProxy 的 backend servers 里面，完成了负载均衡实现的所有工作。如图 5-5 所示。

“好像可以工作了呢。”

等等，负载均衡里怎么能把后端的实例配置成固定参数呢？不招人喜欢的开发经理又提出了第二个需求，而且还有点棘手。

图 5-5 一个添加了负载均衡的 Node. Js 应用和 ELK 组合的实例

首先要面对的问题是，怎么才能保证后端应用容器失败重启或者升级扩展之后，HAProxy 能及时更新自己的配置文件呢？要知道 Docker 容器可没有静态 IP 这个说法（至纱在学习过本书搞级网络实践之前是这样的）。不过如果求助于 GitHub 情况就不一样了，“将军开发者”很快找到一个专门负责配置文件远程修改的组件 confd。

第二个要面对的问题是，哪个组件负责探测应用容器退出或者创建的事件发生然后通知 confd 修改 HAProxy 配置文件呢？这可让“将军开发者”着实花了一番心思。

“这好像是一个服务发现的场景呢。'

没错！所有应用容器都应该把本身 IP 和端口信息注册到 etcd 当中去（etcd 是服务发现存储仓库，将在第 6 章详细介绍），然后依靠 confd 定时查询 etcd 中数据变化来更新 HAProxy 的配置文件。不需要写很多代码，只需要配置一下 confd，然后 build 一个新的 HAProxy 和一个 etcd 容器就足够了。话音未落，“将军开发者”的新系统又上线了。如图 5-6 所示。

这样应该可以了吧。确切地说，这个服务栈不仅拥有了负载均衡和多实例的功能，还能够以一种“发现”的方式向负载均衡节点注册或者解注册应用实例，而且整个过程都是平滑升级的，不会出现服务中断。

“应用健康检查怎么办？”一直在旁默不作声的运维终于坐不住了。

“自发现”机制确实保证了容器自身高可用能力，但是容器中运行着的应用进程实际上并不是完全保险的。最典型的场景是 Java Web Server：当应用异常的时候，Web Server 是完全有可能不退出的，用户只能拿到 4 XX 或者 5 XX 的返回值。所以，在一个真实的应用平台需求下，“垂直监控”是非常有必要的，至少需要能检测到应用访问的返回值是 2 XX。

这还不算完。“将军开发者”虽然构建了一个多实例的应用集群，但生产环境下，这些实例应该将会分布在不同服务器上。这又会带来新的问题，如下所示。

图 5-6 一个添加了负载均衡和自发现特性的 Node. Js 应用和 ELK 组合的实例

❑ 如何保证同一个应用的不同容器实例分布在不同或者指定的宿主节点上？

❑ 当一个宿主节点意外退出的时候，如何保证该节点上的容器实例能够在其他宿主节点上恢复？

❑ 如何比较当前容器实例的运行情况同期望的运行状态的差异，用以决定是否要进行上述高可用动作？

❑ 如何构建一个覆盖“测试- -开发一上线”完整流程的运行机制来充分发挥 Docker 镜像的一致性？

❑ Docker 容器本身的网络应如何配置，尤其是在跨主机环境下怎么处理，是否需要静态 IP？口当开发者创建的镜像非常多时，复杂的镜像关系会大大拖延容器创建和启动速度，这时该如何处理复杂关系对容器性能的影响？

❑ 大量删除操作可能带来不可预知的“孤儿”容器，不光占用大量资源，还可能带来各种莫名异常，造成大量“孤儿”容器的局面该如何应对？

❑ 挂载 volume 的数据该如何进行备份，是否需要实现高可用或跨主机迁移？磁盘写满该如何处理？

❑ 所有 CPU、内存、磁盘资源限制如何才算合理？不合理的资源限制加，上欠考虑的调度策略会不会产生新的资源浪费？

“将军开发者”突然发现，原来说服别人接受自己计划所面临的困难要远比搭建 demo 大得多，尤其是需要涉及现有的生产环境时。事实上，Docker 是运维友好的，相比传统运维方式，通过流程和规范来保证环境一致性的做法，Docker 镜像已经给运维工作带来了很大便利，更不用说它几乎可以忽略的启动时间和简单高效的配置方式了。同样，Docker 更是开发者友好的，光是它伸手即来的安装和启动方式以及灵活通用的 Dockerfile 就足以让传统 PaaS 提供商汗颜。此外，它不存在任何供应商锁定和引人特殊依赖的问题了。可是，就是这样一种对各利益方都友好的技术，在真正用于生产环境时却需要解决一个棘手的问题：如何使用 Docker 特性来提供、升级和简化现有生产环境已经具备的运维能力？

引发这个问题的原因其实很简单，Docker 给工业界带来的不只是一项技术一容器技术已经足够普及了一-它带来的更多是一种思维转变。遗憾的是，Docker 的思考方式与目前任何-项业务运行的方式都不是原生兼容的。

这解释了为什么我们在自建的环境中使用 Docker 能如鱼得水，一旦想要将它推广至生产环境中，就会感到十分棘手。而且我们发现，这些困难往往不是来自容器技术本身，而是与容器相关的网络、存储、集群、高可用等已经在传统场景中得到解决的“泥潭”。为了解决这些问题，我们的“将军开发者”就不得不经历一次又- -次“从小工到专家”的历练，要么学会将 Docker 与传统场景中现有的解决方案集成，要么基于 Docker 技术重新解决-遍这些问题。于是他开始努力研究 HAProxy 和 etcd，开始写 Docker scheduler、health checker、stager、builder. Deployer，终成一代“Docker 大神”。而“容器云”就是在无数这样的 Docker 大神的努力中产生的。

现在就让我们来聊聊“容器云”吧。我们在第 1 章中其实已经提到过，所谓容器云，就是以容器为资源分割和调度的基本单位，封装整个软件运行时环境，为开发者和系统管理员提供用于构建、发布和运行分布式应用的平台。

容器云最直观的形态是一个颇具规模的容器集群，但它与开发者或者运维人员自己维护的“裸”容器集群不同。容器云中会被按功能或者依赖敏感性划分成组，不同容器组之间完全隔离，组内容器允许一定程度共享。容器之间的关系不再简单依靠 docker link 这类原生命令来进行组织，而往往是借助全局网络管理组件来进行统- - ~治理。容器云用户也不需要直接面对 Docker API，而是借助某种控制器来完成用户操作到 Docker 容器之间的调用转译，从而保证底层容器操作对最终用户的友好性。大多数容器云还会提供完善的容器状态健康检查和高可用支持，并尽可能做到旁路控制而非直接侵人 Docker 体系，从而免除“将军开发者”们不得不重复造轮子的尴尬。“容器云”会提供一一个高效、完善、可配置的调度器，调度器可以说是容器云系统需要解决的第一要务，这也正是“将军开发者”最头痛的事情- 他面对的容器越多，运维和管理困难程度往往会呈指数级上升。在接下来的章节中，让我们一起来逐层揭开“容器云”的面纱。

它们或来自于小而美的创业团队，或来自于数- -数=的业界巨头；有的专注于服务发布，有的专注于数据存储；有的只解决编排与运维，有的却几乎可以媲美一个传统 IaaS。但是，无论是那些灵活轻巧的编排：工具还是庞大复杂的容器服务，它们都试图为热爱 Docker 并尝试真正应用 Docker 的“将军开发者”们解决一个核心问题：如何迈过从“容器运行”到“生产使用”之间的这条鸿沟。











