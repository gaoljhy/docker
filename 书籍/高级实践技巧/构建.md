4.1 节介绍的容器化思维推荐以微服务的形式构建容器化应用。在以微服务方式构建的应用中，服务发现、服务状态发布和订阅等模块发挥了连接各个微服务的重要作用。作为高级实践的最后一节，这里要给大家介绍实现服务发现、服务发布与订阅模块的关键技术：高可用的配置中心。为读者进入本书的第二部分了解容器云打下坚实的基础。本节要介绍的是 etcd，一个被众多 PaaS 平台所使用的服务发现配置存储中心。

#### 1. etcd 经典应用场景

etcd 是什么？很多人对这个问题的第-反应可能是它是一个键值存储仓库，却没有重视官方定义的后半句：用于配置共享和服务发现（A highly-available key value store for shared configuration and service discovery.)。

实际上，etcd 作为一个受到 Zookeeper 与 doozer 启发而催生的项目，除了拥有与之类似的功能外，更具有以下 4 个特点。

❑ 简单：基于 HTTP+JSON 的 API，用 curl 命令就可以轻松使用。

❑ 安全：可选 SSL 客户认证机制。

❑ 快速：每个实例每秒支持一千次写操作。

❑ 可信：使用 Raf 算法充分实现了分布式。

由此可见，etcd 主要解决的是分布式系统中数据一致性的问题，而分布式系统中的数据分为控制数据和应用数据。etcd 处理的数据默认为控制数据，对于应用数据，它只推荐处理数据量很小但更新访问频繁的情况。etcd 解决的问题看似单一，但其应用场景却纷繁多样。下面共列出了 8 个较为经典的 etcd 使用场景。希望通过这些场景，读者能充分了解 etcd 的功能。相信经过本章的介绍，读者在理解本书第二部分关于 etcd 的使用时会更为透彻”。

1. 场景一：服务发现

etcd 通常跟服务发现联系到一起，那么服务发现要解决的问题是什么呢？在同一个分布式集群中的进程或服务，互相感知并建立连接，这就是服务发现。从本质上说，服务发现就是想要了解集群中是否有进程在监听 UDP 或 TCP 端口，并且通过对应的字符串（名字）信息就可以进行查找和连接。要解决服务发现的问题，需要有以下三大支柱，缺一不可。

❑ 一个强一致性、高可用的服务存储目录。基于 Raf 算法的 etcd 天生就是这样一个强一致性、高可用的服务存储目录。

❑  一种注册服务和监控服务健康状态的机制。用户可以在 etcd 中注册服务，并且对注册的服务设置 key TTL，定时保持服务的心跳以达到监控健康状态的效果。

❑ 一种查找和连接服务的机制。通过在 etcd 指定的主题下注册的服务也能在对应的主题下被查找到。为了确保连接，可以在每个服务机器上都部署一个 Proxy 模式的 etcd，这样就可以确保能访问 etcd 集群的服务都能互相连接。

图 4-21 所示为服务发现示意图，服务提供者在服务发现仓库注册，服务请求者在仓库中查找，最后通过查找的细节建立链接。


下面来看一下服务发现对应的具体应用场景。

❑ 微服务协同工作架构中，服务动态添加。随着 Docker 容器的流行，多种微服务共同协作，构成一个功能相对强大的架构的案例越来越多。透明化地动态添加这些服务的需求也日益强烈。通过服务发现机制，在 etcd 中注册某个服务名字的目录，在该目录下存储可用的服务节点的 IP。在使用服务的过程中，只要从服务目录下查找可用的服务节点使用即可。如图 4-22 所示，以 Docker 为承载的前端在服务发现目录中查找到可用的中间件，中间件再找到服务后端，以此快速构建起一个动态和高可用的架构。



图 4-22 微服务协同工作

❑ PaaS 平台中应用多实例与实例故障重启透明化。PaaS 平台中的应用一般都有多个实例，通过域名，不仅可以透明地对多个实例进行访问，而且还可以实现负载均衡。但是应用的某个实例随时都有可能故障重启，这时就需要动态地配置域名解析（路由）中的信息。通过 etcd 的服务发现功能就可以轻松解决这个动态配置的问题，如图 4-23 所示。


图 4-23 云平台多实例透明化

2. 场景二：消息发布与订阅

在分布式系统中，最合适的组件间通信方式是消息发布与订阅机制。具体而言，即构建一个配置共享中心，数据提供者在这个配置中心发布消息，而消息使用者则订阅他们关心的主题，一旦相关主题有消息发布，就会实时通知订阅者。通过这种方式可以实现分布式系统配置的集中式管理与实时动态，更新。

3. 场景三：负载均衡

在场景一中也提到了负载均衡，这里提及的负载均衡均指软负载均衡。在分布式系统中，为了保证服务的高可用以及数据的一致性，通常都会部署多份数据和服务，以此达到对等服务，即使其中某一个服务失效了，也不影响使用。这样的实现虽会在-定程度上导致数据写入性能的下降，但却能实现数据访问时的负载均衡。因为每个对等服务节点上都存有完整的数据，所以用户的访问流量就可以分流到不同的机器上。

4. 场景四：分布式通知与协调

这里讨论的分布式通知与协调，与消息发布与订阅有些相似。两者都使用了 etcd 中的 Watcher 机制，通过注册与异步通知机制，实现分布式环境下不同系统之间的通知与协调，从而对数据变更进行实时处理。具体的实现方式通常为：不同系统都在 etcd 上对同一个目录进行注册，同时设置 Watcher 监控该目录的变化”），当某个系统更新了 etcd 的目录，那么设置了 Watcher 的系统就会收到通知，并作出相应处理。

❑ 通过 etcd 进行低耦合的心跳检测。检测系统和被检测系统通过 etcd。上某个目录关联而非直接关联起来，这样可以大大减少系统的耦合性。

❑ 通过 etcd 完成系统调度。某系统由控制台和推送系统两部分组成，控制台的职责是控制推送系统进行相应的推送工作。管理人员在控制台做的一些操作，实际上只需要修改etcd 上某些目录节点的状态，etcd 就会自动把这些变化通知给注册了 Watcher 的推送系统客户端，推送系统再作出相应的推送任务。

❑ 通过 etcd 完成工作汇报。大部分类似的任务分发系统会在子任务启动后，到 etcd 来注册一个临时工作目录，并且定时将自己的进度进行汇报（即将进度写人到这个临时目录），这样任务管理者就能够实时知道任务进度。5. 场景五：分布式锁与竞选etcd 使用 Raf 算法保持了数据的强一致性，某次操作存储到集群中的值必然是全局一致的，因此很容易实现分布式锁。锁服务有两种使用方式，一是保持独占，二是控制时序。

❑ 保持独占。即所有试图获取锁的用户最终只有一个可以得到。etcd 为此提供了一套实现分布式锁原子操作 CAS  (CompareAndSwap）的 API。通过设置 prevExist 值，可以保证在多个节点同时创建某个目录时，只有一个成功，而该用户即可认为是获得了锁。

❑ 控制时序。即所有试图获取锁的用户都会进入等待队列，获得锁的顺序是全局唯- -的，同时决定了队列的执行顺序。etcd 为此也提供了一套 API（自动创建有序键），对一个目录建值时指定为 POST 动作，这样 etcd 会自动在目录下生成一个当前最大的值为键，存储这个新的值（客户端编号），同时还可以使用 API 按顺序列出所有当前目录下的键值。此时这些键的值就是客户端的时序，而这些键中存储的值可以是代表客户端的编号。 

另外，使用分布式锁可以完成Leader竞选。对于一些长时间的CPU计算或者使用1/O 操作，只需要由竞选出的 Leader 计算或处理一一次，再把结果复制给其他 Follower 即可，从而避免重复劳动，节省计算资源。

6. 场景六：分布式队列

分布式队列的常规用法与场景五中所描述的分布式锁的控制时序用法类似，即创建一个先进先出的队列，保证顺序。

另一种比较有意思的实现是在保证队列达到某个条件时再统-按顺序执行。这种方法的实现 可以在/queue这个目录中另外建立一个/queue/condition 节点。

❑ condition 可以表示队列大小。例如，一个大的任务需要在很多小任务就绪的情况下才能执行，每次有一个小任务就绪，就给这个 condition 数字加 1，直到达到大任务规定的数字，再开始执行队列里的一系列小任务，最终执行大任务。

❑ condition 可以表示某个任务是否在队列。这个任务可以是所有排序任务的首个执行程序，也可以是拓扑结构中没有依赖的点。通常，必须执行这些任务后才能执行队列中的其他任务。

❑ condition 还可以表示其他的一类开始执行任务的通知。可以由控制程序指定，当condition 出现变化时，开始执行队列任务。

7. 场景七：集群监控

通过 etcd 来进行监控，实现起来非常简单并且实时性强，主要用到了以下两点特性。

❑ 前面几个场景已经提到了 Watcher 机制，当某个节点消失或有变动时，Watcher 会第一-时间发现并告知用户。

❑ 节点可以设置 TTL key，例如，每隔 30 秒向 etcd 发送一次心跳，代表该节点仍然存活；否则说明节点消失。

这样就可以第-时间检测到各节点的健康状态，以完成集群的监控要求。

3. 场景八：etcd vs. ZooKeeper

阅读了“ZooKeeper 典型应用场景一览”一文的读者可能会发现，etcd 实现的这些功能，ZooKeeper 都能实现。那么为什么要用 etcd 而不直接使用 ZooKeeper 呢？

这是因为与 etcd 相比，ZooKeeper 有如下缺点。

❑ 复杂。ZooKeeper 的部署维护复杂，管理员需要掌握一系列的知识和技能；而 Paxos 强一致性算法也素来以复杂难懂而闻名于世；另外，ZooKeeper 的使用也比较复杂，需要安装客户端，官方只提供了 Java 和 C 两种语言的接口。

❑ Java 编写。Java 本身就偏向于重型应用，它会引人大量的依赖。而运维人员则普遍希望机器集群尽可能地简单，维护起来也不易出错。

❑ 发展缓慢。Apache 基金会项目特有的 Apache Way 在开源界饱受争议，其中一大原因就是基金会结构庞大，管理松散，导致项目发展缓慢。

而 etcd 作为后起之秀，优点也很明显。

❑ 简单。使用 Go 语言编写，部署简单；使用 HTTP 作为接口使用简单；使用 Raft 算法保证强一致性让用户易于理解。

❑ 数据持久化。etcd 默认数据一更新就进行持久化。

❑ 安全。etcd 支持 SSL 客户端安全认证。

etcd 作为一个年轻的项目，正在高速迭代和开发中，这既是一个优点，也是一个缺点。优点在于它的未来具有无限的可能性，缺点是版本的迭代导致其使用的可靠性无法保证，无法得到大项目长时间使用的检验。然而，目前 CoreOS、Kubernetes 和 Cloud Foundry 等知名项目均在生产环境中使用了 etcd，总的来说，etcd 值得尝试。

#### 2. etcd 实现原理
。上一节概括了许多 etcd 的经典应用场景，本节我们将从 etcd 的架构开始深人理解 etcd 的实现原理。

1. Etcd 架构与术语表

etcd 的架构并不复杂，如图 4-24 所示，etcd 主要分为 4 个部分。

❑ HTTP Server：用于处理用户发送的 API 请求以及其他 etcd 节点的同步与心跳信息请求。

❑ Store：用于处理 etcd 支持的各类功能的事务，包括数据索引、节点状态变更、监控与反馈、事件处理与执行等。它是 etcd 对用户提供的大多数 API 功能的具体实现。

❑ Raft: Raft 强一致性算法的具体实现，是 etcd 的核心。

❑ WAL：即 Write AheadLog（预写式日志），它是 etcd 的数据存储方式。除了在内存中存有所有数据的状态以及节点的索引以外，etcd 还通过 WAL 进行持久化存储。WAL 中，所有的数据在提交前都会事先记录日志。Snapshot 是为了防止数据过多而进行的状态快照；Entry 则表示存储的具体日志内容。



图 4-24 etcd 架构图

通常一个用户的请求发送过来，会经由 HTTP Server 转发给 Store 进行具体的事务处理，如果涉及节点的修改，则交给 Raft 模块进行状态的变更、日志的记录，然后再同步给别的 etcd 节点以确认数据提交，最后进行数据的提交，再次同步。

etcd 中涉及较多术语，为便于理解，现罗列如下。

❑ Raft: etcd 所采用的保证分布式系统强一致性的算法。

❑ Node：一个 Raft 状态机实例。

❑ Member：一个 etcd 实例，管理着-一个 Node，可以为客户端请求提供服务。

❑ Cluster：由多个 Member 构成的可以协同工作的 etcd 集群。

❑ Peer：对同一个 etcd 集群中另外一个 Member 的称呼。

❑ Client：向 etcd 集群发送 HTTP 请求的客户端。

❑ WAL：预写式日志，是 etcd 用于持久化存储的日志格式。

❑ Snapshot: etcd 防止 WAL 文件过多而设置的快照，存储 etcd 数据状态。

❑ Proxy: etcd 的一种模式，为 etcd 集群提供反向代理服务。

❑ Leader: Raft 算法中通过竞选而产生的处理所有数据提交的节点。

❑ Follower：竞选失败的节点作为 Raft 中的从属节点，为算法提供强一致性保证。

❑ Candidate: Follower 超过一一定时间接收不到 Leader 的心跳时，转变为 Candidate 开始 Leader竞选。

❑ Term：某个节点成为 Leader 到下一次竞选开始的时间周期，称为一个 Tem。

❑ Index：数据项编号。Raft 中通过 Term 和 Index 来定位数据。

2. 集群化应用与实现原理

etcd 作为一个高可用键值存储系统，天生就是为集群化而设计的。由于 Raf 算法在作决策时需要多数节点的投票，因此 etcd-般部署集群推荐奇数个节点，推荐的数量为 3 个、5 个或者 7 个节点构成一个集群。

● 集群启动

etcd 有 3 种集群化启动的配置方案，分别为静态配置启动、etcd 自身服务发现、通过 DNS 进行服务发现。

根据启动环境，可以选择不同的配置方式。它摒弃了使用配置文件进行参数配置的做法，转而使用命令行参数或者环境变量来配置参数。

♦ 静态配置

这种方式比较适用于离线环境。在启动整个集群之前，如果已经预先清楚所要配置的集群大小，以及集群上各节点的地址和端口信息，那么启动时，可以通过配置 initial-cluster 参数进行 etcd 集群的启动。在每个 etcd 机器启动时，配置环境变量或者添加启动参数的方式如下：

```
ETCD_INITIAL_CLUSTER="infra0=http: //10.0.1.10:2380, infra1=http: //10.0.1.11:2380, infra2=http: //10.0.1.12:2380"

ETCD_INITIAL_CLUSTER_STATE=new -initial-cluster infra0=http: //10.0.1.10:2380, infra1=http: //10.0.1.11:2380, infra2=http: //10.0.1.12:2380 -initial-cluster-state new
```
值得注意的是，initial-cluster 参数中配置的 URL 地址必须与各个节点启动时设置的 initial-advertise-peer-urls 参数相同”。

如果所在的网络环境配置了多个 etcd 集群，为了避免意外发生，最好使用 initial-cluster-token 参数为每个集群单独配置一个 token 认证，这样就可以确保每个集群和集群的成员都拥有独特的 ID。

综上所述，如果要配置包含 3 个 etcd 节点的集群，那么在 3 个机器上的启动命令分别如下所示。

```
etcd -name infra0 -initial-advertise-peer-urls http://10.0.1.10:2380 \
-listen-peer -urls http: //10.0.1.10:2380 \
-initial-cluster -token etcd-cluster-1 \
-initial-cluster infrao=http://10.0. 1.10:2380, infra1=http://10.0.1.11:2380, infra2=http://10.0.1.12:2380 \
-initial-cluster-state new

etcd -name infra1 -initial-advertise-peer -urls http://10.0.1.11:2380 \
-listen-peer-urls http: //10.0.1.11:2380 \
-initial-cluster-token etcd-cluster-1 \
-initial-cluster infrao=http: //10.0.1.10:2380, infra1=http://10.0.1.11:2380, infra2=http://10.0.1.12:2380
-initial-cluster-state new

etcd -name infra2 -initial-advertise-peer-urls http://10.0.1.12:2380 \
-listen-peer-urls http://10.0.1.12:2380 \
-initial-cluster -token etcd-cluster-1 \
-initial-cluster infra0=http://10.0.1.10:2380, infra1=http://10.0.1.11:2380, infra2=http://10.0.1.12:2380 \
-initial-cluster-state new
```
在初始化完成后，etcd 还提供动态增、删、改 etcd 集群节点的功能，这个需要用到 etcdctl 命令进行操作。

♦ etcd 自发现模式

通过自发现的方式启动 etcd 集群，需要事先准备一个 etcd 集群。如果已经有一个 etcd 集群（假设 etcd 的 URL 为 ttps: //myetcd. Local），首先可以执行如下命令设定集群的大小 (假设为 3) 。

```
curl -X PUT https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bfoef5a6fco257c817fofb83/_config/size -d value=3
```
然后要把这个URL地址hp://myetcd.loca/v2/keys/discovery/6c007a14875d53d9bfoef5a6fco257c817fofb83 作为 discovery参数来启动 etcd。这样节点会自动使用https://myetcd.local/v2/keys/discovery/6c007a14875d53d9bfoef5a6fco257c817fofb83 目录进行etcd 的注册和发现服务。

所以最终在某个机器上启动 etcd 的命令如下：

```
etcd -name infra0 -initial-advertise-peer -urls http: //10.0.1.10:2380 \
-listen-peer-urls http: //10.0.1.10:2380 \
-discovery 
https://myetcd.local/v2/keys/discovery/6c007a14875d53dgbfoef5a6fc0257c817f0fb83
```
如果在本地没有可用的 etcd 集群，etcd 官网提供了一个可以用公网访问的 etcd 存储地址，可以通过如下命令得到 etcd 服务的目录，并把它作为 discovery 参数使用。

```
curl https://discovery.etcd.io/new?size=3
https: //discovery.etcd.io/3e86b59982e49066c5d813af1c2e2579cbf573de
```
同样地，当完成了集群的初始化后，这些信息就失去了作用。如果需要增加节点，可以使用 etcdct1 来进行操作。为了安全，在每次启动新的 etcd 集群时，请务必使用新的 discovery token 进行注册。另外，如果初始化时启动的节点超过了指定的数量，多余的节点会自动转化为 Proxy 模式的 etcd。

♦ DNS 自发现模式

etcd 还支持使用 DNS SRV 记录进行启动。关于 DNS SRV 记录如何进行服务发现，可以参阅 RFC2782"，所以，首先需要在 DNS 服务器上进行相应的配置。

❑ 开启 DNS 服务器上的 SRV 记录查询，并添加相应的城名记录，使得查询结果如下所示。
```
dig +noall +answer SRV infra0.example.com infra1.example.com infra2.example.com

_etcd-server.tcp.example.com. 300 IN SRV 0 0 2380 infra0.example.com. 
_etcd-server.tcp.example.com. 300 IN SRV 0 0 2380 infra1.example.com. 
_etcd-server.tcp.example.com. 300 IN SRV 0 0 2380 infra2.example.com. 
```
❑ 分别为各个域名配置相关的 A 记录，指向 etcd 核心节点对应的机器 IP，使得查询结果如下所示。
```
dig +noall +answer infra0.example.com infra1.example.com infra2.example.com

infra0.example.com. 300 IN A 10.0.1.10 
infra1.example.com. 300 IN A 10.0.1.11
infra2.example.com. 300 IN A 10.0.1.12 
```
做好了上述两步 DNS 的配置，就可以使用 DNS 启动 etcd 集群了。配置 DNS 解析的 URL 参数为 -discovery-srv，其中某一个节点的启动命令如下：

```
etcd -name infra0 \
-discovery-srv example.com \
-initial-cluster-token etcd-cluster-1 \
-initial-advertise-peer-urls http://infra0.example.com:2380 \ 
-initial-cluster-state new \
-advertise-client-urls http://infra0.example.com:2379 \
-listen-client-urls http://infra0.example.com:2379 \ 
-listen-peer-urls http://infra0.example.com:2380
```
当然也可以直接把节点的域名改成 IP 来启动。

● 运行时节点变更

etcd 集群启动完毕后，可以在运行的过程中对集群进行重构，包括核心节点的增加、删除、迁移、替换等。运行时重构使得 etcd 集群无须重启即可改变集群的配置。

只有在集群中多数节点正常的情况下，才可以进行运行时的配置管理。因为配置更改的信息也会被 etcd 当成一个信息存储和同步，如果集群的多数节点遭损坏，集群就失去了写人数据的能力。在配置 etcd 集群数量时，强烈推荐至少配置 3 个核心节点，配置数目越多，可用性越强。

♦ 节点迁移、替换

当节点所在的机器出现硬件故障或者节点出现数据目录损坏等问题，导致节点永久性地不可恢复时，就需要对节点进行迁移或者替换。当一个节点失效以后，必须尽快修复，因为 etcd 集群正常运行的必要条件是集群中多数节点都正常工作。迁移一个节点需要进行以下 4 步操作：

❑ 暂停正在运行的节点程序进程；

❑ 把数据目录从现有机器复制到新机器；

❑ 使用 API 更新 etcd 中对应节点，指向机器的 URL 记录更新为新机器的 IP;

❑ 使用同样的配置项和数据目录，在新的机器上启动 etcd。

♦ 节点增加

增加节点可以让 etcd 的高可用性更强。例如，如果配置有 3 个节点，那么最多允许一个节点失效；当配置有 5 个节点时，就可以允许有两个节点失效。同时，增加节点还可以让 etcd 集群具有更好的读性能。因为 etcd 的节点都是实时同步的，每个节点上都存储了所有的信息，所以增加节点可以从整体上提升读的吞吐量。增加一个节点需要进行以下两步操作：

❑ 在集群中添加这个节点的 URL 记录，同时获得集群的信息；

❑ 使用获得的集群信息启动新的 etcd 节点。

♦ 节点移除

有时不得不在提高 etcd 的写性能和增加集群高可用性上进行权衡。Leader 节点在提交-一个写记录时，会把这个消息同步到每个节点上，当得到多数节点的同意反馈后，才会真正写人数据。所以节点越多，写入性能越差。当节点过多时，可能需要移除其中的一个或多个。移除节点非常简单，只需要一步操作，就是把集群中这个节点的记录删除，然后对应机器上的该节点就会自动停止。

♦ 强制性重启集群

当集群超过半数的节点都失效时，就需要通过手动的方式，强制性让某个节点以自身为 Leader，利用原有数据启动一个新集群。此时需要进行以下两步操作：

❑ 备份原有数据到新机器；

❑ 使用-force-new-cluster 和备份的数据重新启动节点。

```
注意强制性重启是一个迫不得已的选择，它会破坏一致性协议保证的安全性，也就是说，如果操作时集群中尚有其他节点在正常工作，就会出错，所以在操作前请务必要保存好数据。
```

3. 代理模式与实现原理

Proxy 模式是 etcd 的另-种形态，Proxy 模式下的 etcd 作为一个反向代理把客户的请求转发给可用的 etcd 集群。官方推荐的方式是，在每一台机器都部署一个 Proxy 模式的 etcd 作为本地服务，如果这些 etcd Proxy 都能正常运行，那么你的服务发现集群必然是稳定可连接的。图 4-25 为 Proxy 模式示意图。

图 4-25 Proxy 模式示意图

可见，Proxy 并不是直接加入到符合强一-致性的 etcd 集群中，它没有增加集群的可靠性，也没有降低集群的写入性能。

那么，为什么要有 Proxy 模式而不是直接增加 etcd 核心节点呢？实际上，etcd 每增加一个核心节点（peer），都会给 Leader 节点增加- -定程度的负担（包括网络、CPU 和磁盘负载）。因为每次信息的变化都需要进行同步备份。增加 etcd 的核心节点固然可以让整个集群具有更高的可靠性，但当其数量达到一定程度以后，增强可靠性带来的好处就变得不那么明显了，反而降低了集群写人同步的性能。因此，增加一个轻量级的 Proxy 模式 etcd 节点是对直接增加 etcd 核心节点的一个有效代替。

熟悉 etcd 0.4.61 旧版本的用户会发现，Proxy 模式实际上取代了原先具备转发代理功能的 Standby 模式。此外，在核心节点因为故障导致数量不足时，还会从 Standby 模式转为核心节点。而当故障节点恢复时，若 etcd 的核心节点数量已达到预设值，则前述节点会再次转为 Standby 模式。

但是在新版 etcd 中，只在最初启动 etcd 集群的过程中，若核心节点的数量已满足要求，则自动启用 Proxy 模式；反之则并未实现，主要原因如下。

❑ etcd 是用来保证高可用的组件，因此它所需要的系统资源（包括内存、硬盘、CPU 等）都应该得到充分保障。任由集群的自动变换随意地改变核心节点，无法让机器保证性能。所以 etcd 官方鼓励大家在大型集群中为运行 etcd 准备专有机器集群。

❑ etcd 集群是支持高可用的，部分机器故障并不会导致功能失效，所以在机器发生故障时，管理员有充分的时间对机器进行检查和修复。

❑ 自动转换使得 etcd 集群变得更为复杂，尤其是在如今 etcd 支持多种网络环境的监听和交互的情况下，在不同网络间进行转换，更容易发生错误，导致集群不稳定。

基于上述原因，目前 Proxy 模式有转发代理功能，但不会进行角色转换。

4. Etcd 数据存储原理

etcd 的存储分为内存存储和持久化（硬盘）存储两部分。内存中的存储除了顺序化地记录所有用户对节点数据变更的记录外，还会对用户数据进行索引、建堆等方便查询的操作。而持久化则使用 WAL 进行记录存储。

在 WAL 的体系中，所有的数据在提交之前都会进行日志记录。在 etcd 的持久化存储目录中有两个子目录。一个是 WAL，存储着所有事务的变化记录；另一个则是 Snapshot，用于存储某一个时刻 etcd 所有目录的数据。通过 WAL 和 Snapshot 相结合的方式，etcd 可以有效地进行数据存储和节点故障恢复等操作。

也许读者会有这样的疑问，既然已经在 WAL 实时存储了所有的变更，为什么还需要 Snapshot 呢？随着使用量的增加，WAL 存储的数据会急剧增加，为了防止磁盘空间不足，etcd 默认每一万条记录做一次 Snapshot，经过 Snapshot 以后的 WAL 文件就可以删除。通过 API 可以查询的历史 etcd 操作默认为一千条。

首次启动时，etcd 会把启动的配置信息存储到 data -dir 参数指定的数据目录中。配置信息包括本地节点 ID、集群 ID 和初始时的集群信息。用户需要避免 etcd 从一个过期的数据目录中重新启动，因为使用过期的数据目录启动的节点不能与集群中的其他节点保持一~致性。例如，之前已经记录并同意 Leader 节点存储某个信息，重启后又向 Leader 节点申请这个信息。所以，为了最大化集群的安全性，一旦有任何数据有损坏或丢失的可能性，就应该把这个节点从集群中移除，然后加入一个不带数据目录的新节点。

WAL 最大的作用是记录了整个数据变化的全部历程。在 etcd 中，所有数据的修改在提交前，都要先写人到 WAL 中。使用 WAL 进行数据的存储使 etcd 拥有如下两个重要功能。

❑ 故障快速恢复。当数据遭到破坏时，就可以通过执行所有 WAL 中记录的修改操作，快速从最原始的数据恢复到数据损坏前的状态。

❑ 数据回滚或重做。因为所有的修改操作都被记录在 WAL 中，在需要回滚或重做时，只需要反向或正向执行日志中的操作即可。

5. Etcd 核心算法 Raft

在 etcd 中，Raft 包就是对 Raft 强一致性算法的具体实现，是 etcd 的核心。关于 Raf 算法的讲解，有兴趣的读者可以阅读一下 Raf 算法论文”。本文不再对 Raft 算法进行详细描述，而是结合 etcd，针对算法中的一些关键内容以问答的形式进行讲解。

● Raft 中一个任期是什么意思

在 Raft 算法中，从时间上讲，一个任期（term)（见图 4-26) 即从某一次竞选开始到下一次竞选开始。从功能上讲，如果 Follower 接收不到 Leader 节点的心跳信息，就会结束当前任期，变为Candidate 发起竞选，这有助于在 Leader 节点发生故障时集群的恢复。



图 4-26 任期示意图

发起竞选投票时，任期值小的节点不会竞选成功。如果集群不出现故障，那么一个任期将无限延续下去。而投票出现冲突则有可能直接进入下一任再次竞选。

● Raft 状态机是怎样切换的

Raft 刚开始运行时，节点默认进人 Follower 状态，等待 Leader 发来心跳信息。若等待超时，则状态由 Follower 切换到 Candidate 进入下一轮任期发起竞选，等到收到集群多数节点的投票时，该节点转变为 Leader。Leader 节点有可能出现网络等故障，导致别的节点发起投票成为新任期的 Leader，此时原先的老 Leader 节点会切换为 Follower。Candidate 在等待其他节点投票的过程中，如果发现别的节点已经竞选成功成为 Leader 了，也会切换为 Follower 节点。图 4-27 所示为 Raft 状态机。



图 4-27 Raft 状态机

● 如何保证最短时间内竞选出 Leader，以防止竞选冲突

从图 4-27 中可以看到，在 Candidate 状态下，有一个“心跳超时”，这是个随机值，也就是说，每个机器成为 Candidate 以后，超时发起新一轮竞选的时间是各不相同的，这就会出现一个时间差。在时间差内，如果 Candidatel 收到的竞选信息比自己发起的竞选信息的任期值大（即对方为新一轮任期），并且新一轮想要成为 Leader 的 Candidate2 包含了所有提交的数据，那么 Candidatel 就会投票给 Candidate2, 这样就保证了出现竞选冲突的概率很小。

● 如何防止别的 Candidate 在遗漏部分数据的情况下发起投票成为 Leader

在 Raft 竞选的机制中，使用随机值决定超时时间，第一个超时的节点就会提升任期编号发起新一轮投票。一般情况下，别的节点收到竞选通知就会投票。但如果发起竞选的节点在上-一个任期中保存的已提交数据不完整，节点就会拒绝投票给它。通过这种机制就可以防止遗漏数据的节点成为 Leader。

● Raft 某个节点宕机后会如何

通常情况下，如果是 Follower 节点宕机，且剩余可用节点数量超过总节点数的一半，集群可以几乎不受影响地正常工作。如果是 Leader 节点宕机，那么 Follower 节点会因为收不到心跳而超时，发起竞选获得投票，成为新一轮任期的 Leader，继续为集群提供服务。需要注意的是，etcd 目前没有任何机制会自动去变化整个集群的总节点数量，即如果没有人为地调用 API，etcd 宕机后的节点仍然被计算在总节点数中，任何请求被确认需要获得的投票数都是这个总数的一-半以上。图 4-28 所示为节点宕机。



图 4-28 节点宕机

● 为什么 Raft 算法在确定可用节点数量时不需要考虑拜占庭将军问题

拜占庭将军问题中提出，允许 n 个节点宕机还能提供正常服务的分布式架构，需要的总节点数量为 3n+1, 而 Raft 只需要 2n+1 就可以了。其主要原因在于，拜占庭将军问题中存在数据欺骗的现象，而 etcd 中假设所有的节点都是诚实的。etcd 在竞选前需要告诉别的节点自身的任期编号以及前一轮任期最终结束时的 index 值，这些数据都是准确的，其他节点可以根据这些值决定是否投票。另外，etcd 严格限制 Leader 到 Follower 这样的数据流向，以保证数据- -致不出错。

● 用户从集群中哪个节点读写数据

Raft 为了保证数据的强一-致性，所有的数据流向都是一个方向，从 Leader 流向 Follower，即所有 Follower 的数据必须与 Leader 保持一致，如果不一致则会被覆盖。也就是说，所有用户更新数据的请求都最先由 Leader 获得并保存下来，然后通知其他节点将其保存，等到大多数节点反馈时再把数据提交。一个已提交的数据项才是 Raft 真正稳定存储下来的数据项，不再被修改，最后再把提交的数据同步给其他 Follower。因为每个节点都有 Raft 已提交数据准确的备份”，所以任何一个节点都可以处理读请求。

● etcd 实现的 Raft 算法的性能如何

单实例节点支持每秒一千次数据写人。随着节点数目的增加，数据同步会因为网络延迟越来越慢；而读性能则会随之提升，因为每个节点都能处理用户的读请求。

3. Etcd 的 API 一览

etcd 中处理 API 的包称为 Store，顾名思义，Store 模块就像-一个商店一样把 etcd 已经准备好的各项底层支持加工起来，为用户提供各式各样的 API 支持，处理用户的各项请求。要理解 Store，就要从 etcd 的 API 人手。打开 etcd 的 API 列表，我们可以看到如下 API，它们都是对 etcd 存储的键值进行的操作，亦即 Store 提供的内容。API 中提到的目录（directory）和键（key)，。上文中有时也称为 etcd 节点。

为 etcd存储的键赋值：
```
curl http: //127.0.0.1:2379/v2/keys/message -XPUT -d value="Hello world"
{
    "action": "set",
    "node": {
      " createdIndex": 2,
      "key": "/message",
      "modifiedIndex": 2,
      "value": "Hello world"
    }
}
```
反馈的内容含义如下。

❑ action：刚刚进行的动作名称。

❑ node.key：请求的 HTTP 路径。etcd 使用一个类似文件系统的方式来反映键值存储的内容。

❑ node.value：刚刚请求的键所存储的内容。

❑ node.createdIndex: etcd 节点每次发生变化时，该值会自动增加。除了用户请求外，etcd内部运行（如启动、集群信息变化等）也可能会因为节点有变动而引起该值的变化。

❑ node. ModifiedIndex：类似 node. CreatedIndex，能引起该值变化的操作包括 set、delete、update、create、compareAndSwap 或compareAndDelete。

查询 etcd 某个键存储的值：
```
curl http: //127.0.0.1:2379/v2/keys/message
```
修改键值与创建新值几乎相同，但是反馈时会有一个 prevNode 值反映修改前存储的内容：
```
curl http: //127.0.0.1:2379/v2/keys/message -XPUT -d value= "Hello etcd“
```
删除一个值：
```
curl http: //127.0.0.1:2379/v2/keys/message -XDELETE
```
对一个键进行定时删除。etcd 中对键进行定时删除，设定一个 tt1 值，当这个值到期时，键就会被删除。反馈的内容会给出 expiration 项告知超时时间，以及 ttl 项告知设定的时长。
```
curl http: //127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -d ttl=5
```
取消定时删除任务：
```
curl http: //127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -d tt1= -d prevExist=true
```
对键值修改进行监控。etcd 提供的这个 API 让用户可以监控一个值或者递归式地监控一个目录及其子目录的值，当目录或值发生变化时，etcd 会主动通知。
```
curl http: //127.0.0.1:2379/v2/keys/foo?wait=true
```
对过去的键值操作进行查询。类似上面提到的监控，在其基础上指定过去某次修改的索引编号，就可以查询历史操作。默认可查询的历史记录为一千条。
```
curl 'http: //127.0.0.1:2379/v2/keys/foo?wait=true&waitIndex=7'
```
自动在目录下创建有序键。在对创建的目录使用 POST 参数时，会自动在该目录下创建一个以 createdIndex 值为键的值，这样就相当于根据创建时间的先后进行了严格排序。该 API 对分布式队列这类场景非常有用。
```
curl http: //127.0.0.1:2379/v2/keys/queue -XPOST -d value=Job1
{
    "action": "create",
    "node": {
        "createdIndex": 6，
        "key": "/queue/6"，
        "modifiedIndex": 6,
        "value": "Job1"
    }
}
```
按顺序列出所有创建的有序键：

```
curl -S 'http: //127.0.0.1:2379/v2/keys/queue?recursive=true&sorted=true'
```
创建定时删除的目录与定时删除某个键类似。如果目录因为超时被删除了，其下的所有内容也会自动超时删除：
```
curl http: //127.0.0.1:2379/v2/keys/dir -XPUT -d ttl=30 -d dir=true
```
刷新超时时间：
```
curl http: //127.0.0.1:2379/v2/keys/dir -XPUT -d ttl=30 -d dir=true -d prevExist=true
```
自动化 CAS  (Compare and-Swap）操作。etcd 强一 ~致性最直观的表现就是这个 API，通过设定条件，阻止节点二次创建或修改。即当且仅当 CAS 的条件成立，用户的指令被执行。条件有以下几个。

❑ prevValue：表示先前节点的值，如果值与提供的值相同才允许操作。

❑ prevIndex：表示先前节点的编号，如果编号与提供的校验编号相同才允许操作。

❑ prevExist：判断先前节点是否存在，如果存在则不允许操作。这个常常被用于分布式锁的唯一获取。

假设先设定了 foo 的值 curl http: //127.0.0.1:2379/v2/keys/foo -XPUT -d value=one，然后再进行操作 curl http: //127 .0.0.1:2379/v2/keys/foo?prevExist=false -XPUT -d value=three，就会返回创建失败的错误。

条件删除（Compare and-Delete）与 CAS 类似，条件成立后才能删除。

创建目录：
```
curl http: //127.0.0.1:2379/v2/keys/dir -XPUT -d dir=true
```
列出目录下所有的节点信息，最后以“/”结尾，还可以通过 recursive 参数递归列出所有子目录的信息。
```
curl http: //127.0.0.1:2379/v2/keys/
```
删除目录。默认情况下只允许删除空目录，如果要删除有内容的目录需要加上 recursive=true 参数。
```
curl 'http: //127.0.0.1:2379/v2/keys/foo_ dir? dir=true' -XDELETE
```
创建一一个隐藏节点。命名时名字以下划线“”开头，默认为隐藏键。
```
curl http: //127 .0.0.1:2379/v2/keys/_. Message -XPUT -d value="Hello hidden world"
```
通过以上内容阅读，相信读者已经对 Store 的工作内容有了基本的了解。它对 etcd 下存储的数据进行加工，创建出如文件系统殷的树状结构供用户快速查询。它有一个 Watcher 用于节点变更的实时反馈，还需要维护一个 WatcherHub 对所有 Watcher 订阅者进行通知的推送。同时，它还维护了一个由定时键构成的小顶堆，快速返回下一个要超时的键。最后，所有这些 API 的请求都以事件的形式存储在事件队列中等待处理。

通过从应用场景到原理分析的一系列解读，我们了解到 etcd 并不是一个简单的分布式键值存储系统。它解决了分布式场景中最为常见的数据一致性问题，为服务发现提供了一个稳定、高可用的消息注册仓库，为以微服务协同工作的架构提供了无限的可能。在本书的后半部分，我们所构建的容器云几乎都把 etcd 作为不可或缺的一部分。


